{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scene:**\n",
    "\n",
    "Its 3pm and your supervisor has just handed you their old Fortran77 code that they swear \"solved this problem in the 80s\" and \"is really smartly written and easy to follow\". After the meeting you take one look at the code and realize it doesn't. And it's not. \n",
    "\n",
    "But, you said you'd have results by the group meeting the following day, so lets see if we can understand what it is doing, fix it up, and get some results!\n",
    "\n",
    "$_{\\rm Also,\\ this\\ code\\ has\\ somehow\\ already\\ been\\ converted\\ into\\ python\\ 3.\\ who\\ knows}$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this question we will try to develop some smart coding practices, and try to improve upon some poorly written code.**\n",
    "\n",
    "You are provided with the following code in this workbook, \n",
    "which is both memory and computationally inefficient (and poorly commented)\n",
    "\n",
    "Your task is to speed the code up as much as possible, and to make it as memory efficient as possible.\n",
    "Also, you should comment \"important\" lines with what operations they seem to be performing\n",
    "\n",
    "Hints:\n",
    "\n",
    "**1.) Try to get rid of every single for loop (vectorize everything you can)**\n",
    "\n",
    "**2.) Get rid of duplicate memory allocation**\n",
    "\n",
    "> e.g. \n",
    "\n",
    "> array1 = np.zeros((10,10))\n",
    "\n",
    "> array2 = array1 * 2.0\n",
    "\n",
    "> array3 = array2**2 \n",
    "\n",
    "> Instead just use array1 = array1 * 2.0 ; array1 = array1**2, etc.\n",
    "\n",
    "\n",
    "**Marks will be based on:**\n",
    "\n",
    "1.) run time of your improved code compared to the original (0 for loops are needed)\n",
    "\n",
    "2.) memory usage of your code compared to the original\n",
    "\n",
    "3.) Documentation. Fix missing comments (hint: look for lines that start with \"###\"), and feel free to add additional ones if you feel they are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets first test some good coding practices here:**\n",
    "\n",
    "1.) **Never use for loops unless you have to - super slow! Vectorize everything**\n",
    "\n",
    "e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data created\n",
      "For loop: total = 25002157026354 in time = 30 seconds\n",
      "Vectorized: total = 25002157026354 in time = 0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make random data arrays\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "N = 10000000\n",
    "A = np.arange(N)\n",
    "B = np.random.uniform(size=N)\n",
    "\n",
    "print(\"data created\")\n",
    "\n",
    "# test time to use for loop vs vectorized version\n",
    "\n",
    "# Bad Way\n",
    "start = time.time()\n",
    "total = 0\n",
    "for i in range(N):\n",
    "    total += A[i] * B[i]\n",
    "end = time.time()\n",
    "print(\"For loop: total = %d in time = %d seconds\"%(total, end-start))\n",
    "\n",
    "# Good Way\n",
    "start = time.time()\n",
    "total = np.sum(A*B)\n",
    "end = time.time()\n",
    "print(\"Vectorized: total = %d in time = %d seconds\"%(total, end-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) **Don't convert lists to arrays/array to lists unless necessary for some reason**\n",
    "\n",
    "e.g.:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List/For loop: total = 25002157026354 in time = 10 seconds\n",
      "Array Vectorized: total = 25002157026354 in time = 0 seconds\n"
     ]
    }
   ],
   "source": [
    "N = 10000000\n",
    "\n",
    "# Bad Way\n",
    "start = time.time()\n",
    "A = []\n",
    "for i in range(N):\n",
    "    A_i = np.random.uniform()\n",
    "    A.append(A_i)\n",
    "\n",
    "A = np.array(A)\n",
    "end = time.time()\n",
    "print(\"List/For loop: total = %d in time = %d seconds\"%(total, end-start))\n",
    "\n",
    "\n",
    "# Good Way\n",
    "start = time.time()\n",
    "A = np.random.uniform(size=N)\n",
    "end = time.time()\n",
    "print(\"Array Vectorized: total = %d in time = %d seconds\"%(total, end-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) **Don't duplicate arrays unless you actually need the multiple versions**\n",
    "\n",
    "e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.uniform(size=(100,100))\n",
    "B = A*2\n",
    "C = B**2\n",
    "\n",
    "# you've now tripled the memory usage to calculate C from A. Unless you actually need A and B later, don't do this. \n",
    "# Just do:\n",
    "A = np.random.uniform(size=(100,100))\n",
    "A = A*2\n",
    "A = A**2\n",
    "\n",
    "# or \n",
    "\n",
    "A = np.random.uniform(size=(100,100))\n",
    "A *= 2\n",
    "A = A**2\n",
    "\n",
    "# or whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Outline**\n",
    "The code you will be working with is a mockup of a three dimensional \"large scale structure survey\", or a \"mock\" observation. Using this code we want to populate our field of view with the flux from a number (Nhalo) of dark matter halos. \n",
    "\n",
    "Each of these halos will be given:\n",
    "\n",
    "1.) a randomly drawn position in (ra [deg], dec [deg], distance [Mpc (comoving)])\n",
    "\n",
    "2.) a randomly drawn Mass in [Msun], drawn from an analytical Halo Mass Function (HMF) \n",
    "\n",
    "\n",
    "For each of these halos you will calculate a Luminosity, based on the given Mass-to-Luminosity relation mass_to_luminosity(mass). \n",
    "\n",
    "You will then bin the luminosity of these halos into a three dimensional map/array of size (npix_x, npix_y, npix_z) which represents (ra, dec, distance - aka a three dimensional data cube, where each voxel (3D pixel) represents the luminosity coming from that region of space.)\n",
    "\n",
    "You will then perform a simple \"analysis\" of this map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**first, a bit on what a \"dark matter halo mass function\" is:**\n",
    "\n",
    "The Halo Mass function describes the number of dark matter halos of a given mass M\n",
    "\n",
    "For this example we will use a simplified version of the form HMF = M * np.exp(-M/Mstar), where M is the mass of a halo\n",
    "\n",
    "How do we randomly draw halo mass values according to a distribution? **This is a very common type of excercise for reserch/job interviews.**\n",
    "\n",
    "Probability distrution function PDF: \n",
    "\n",
    "$f(x)= A x exp(-x/b)$\n",
    "\n",
    "where $A = \\int_0^{inf} f(x) dx$\n",
    "\n",
    "and b is given\n",
    "\n",
    "Cumlative distribution function CDF: \n",
    "\n",
    "$ F(x) = \\int_0^x f(x)dx $\n",
    "\n",
    "so\n",
    "\n",
    "$F(x) = Ab(b-(x+b)exp(-x/b))$\n",
    "\n",
    "Cannot invert this analytically, so must do numerically.\n",
    "\n",
    "With the inverted CDF, CDFinv, we can simply draw a uniform random number in the range (0,1), plug this into the CDFinv, and it will return samples drawn from any PDF that we desire!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd4704235855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNhalo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmap_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mFlux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special\n",
    "from scipy import interpolate\n",
    "import time\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "# Halo Parameters\n",
    "Nhalo = 100000000 # set to 100000000 for final run (Note large numbers will probably not even work with the original poorly written code)\n",
    "\n",
    "# Map parameters\n",
    "npix = 1000 # set to 1000 for final run\n",
    "\n",
    "fov_x = 10 # in degrees\n",
    "fov_y = 10 # in degrees\n",
    "chi_min = 0. # minimum distance\n",
    "chi_max = 3.e3 # maximum distance\n",
    "\n",
    "###v\n",
    "dx_pix = fov_x/npix\n",
    "dy_pix = fov_y/npix\n",
    "dz_pix = (chi_max - chi_min)/npix\n",
    "\n",
    "ra = np.random.uniform(-fov_x/2, fov_x/2, Nhalo)\n",
    "dec = np.random.uniform(-fov_y/2, fov_y/2, Nhalo)\n",
    "chi = np.random.uniform(chi_min, chi_max, Nhalo)\n",
    "### \n",
    "\n",
    "# Set max and Min mass so integral converges\n",
    "Mmin  = 0.\n",
    "Mmax  = 1.e16\n",
    "Mstar = 1.e13\n",
    "\n",
    "###??\n",
    "hmf_func = lambda M: M*np.exp(-M/Mstar)\n",
    "norm_pdf, err = integrate.quad(hmf_func, Mmin, Mmax)\n",
    "\n",
    "hmf_pdf = lambda x: 1./norm_pdf * x*np.exp(-x/Mstar)\n",
    "\n",
    "###??\n",
    "hmf_cdf = lambda x: 1./norm_pdf * Mstar * (Mstar - (x + Mstar)*np.exp(-x/Mstar))\n",
    "\n",
    "# Make array of masses\n",
    "M = np.linspace(Mmin, Mmax, 10000)\n",
    "\n",
    "# Get CDF value at each M\n",
    "CDF_of_M = hmf_cdf(M)\n",
    "\n",
    "### ??\n",
    "CDF_of_M_inv = interpolate.interp1d(CDF_of_M, M)\n",
    "\n",
    "# Does drawing from this give the correct mass function?? Check \n",
    "\n",
    "###v\n",
    "mass = CDF_of_M_inv(np.random.uniform(size=Nhalo))\n",
    "\n",
    "###v\n",
    "mass_to_luminosity = lambda x: (x/Mstar)**2.4 \n",
    "\n",
    "Lum = mass_to_luminosity(mass)\n",
    "Flux = Lum/4/np.pi/chi**2\n",
    "\n",
    "###v?\n",
    "map_1 = np.zeros((npix,npix,npix))\n",
    "i = ((ra +fov_x/2) // dx_pix).astype(int)\n",
    "j = ((dec+fov_y/2) // dy_pix).astype(int)\n",
    "k = (chi // dz_pix).astype(int)\n",
    "\n",
    "for h in range(Nhalo):\n",
    "    map_1[i[h], j[h], k[h]] += Flux[h]\n",
    "                \n",
    "\n",
    "###v\n",
    "    \n",
    "chi_cut = 500\n",
    "map_sum = np.zeros((npix,npix))\n",
    "\n",
    "#k would range from 0 to npix-1 but we pick out k's that dont make the cut\n",
    "k = np.arange(0,int(chi_cut/dz_pix)+1, dtype=int) # values of k's that DON'T make the cut\n",
    "map_sum = np.copy(map_1) # copy map_1 or else we will mutate map_1\n",
    "map_sum[:,:,k] = 0 # all values before axis 2 index k will be zero \n",
    "map_sum = np.sum(map_sum, axis=2) # sum all values in axis 2\n",
    "npix_include = npix-len(k) # number of k's that DO make the cut\n",
    "\n",
    "map_mean = map_sum/npix_include\n",
    "hist, bin_edges = np.histogram(map_mean)\n",
    "\n",
    "tend = time.time()\n",
    "\n",
    "print(\"total runtime = %d seconds\" % (tend-tstart))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the map \"map_mean\"\n",
    "\n",
    "# What does this map_mean represent? Plot it. \n",
    "\n",
    "# Take the histogram of the pixel intensities. Plot that\n",
    "\n",
    "# find the indices of the 10 brightest pixels. Print those out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
